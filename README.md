### ğŸ‘¨â€ğŸ« Santander Customer Satisfaction - Machine Learning from Disaster
kaggleì—ì„œ ì œê³µí•˜ëŠ” Binary Classification with a Bank Churn Datasetì„ EDAì™€ model í•™ìŠµì„ í†µí•´ ê³ ê° ì´íƒˆ í™•ë¥ ì„ ì˜ˆì¸¡í•˜ëŠ” í”„ë¡œì íŠ¸

---
### â²ï¸ ë¶„ì„ ê¸°ê°„
2024.09.10 - 2024.09.13

---

### ğŸ“ ì†Œê°œ
Binary Classification with a Bank Churn Datasetì€ ì´ì „ì— ì§„í–‰í–ˆë˜ Santander Customer Satisfaction dataì™€ ë¹„ìŠ·í•˜ê²Œ ê³ ê° ì´íƒˆì— ëŒ€í•œ ì˜ˆì¸¡ì„ í•˜ëŠ” ë¬¸ì œì´ë‹¤. í•˜ì§€ë§Œ featureê°€ ê°€ë ¤ì ¸ ìˆëŠ” ê²ƒì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— Feature Engineeringì„ ì§„í–‰í•  ë•Œ featureë“¤ì„ ìœ ìš©í•˜ê²Œ ì´ìš©í•  ìˆ˜ ìˆë‹¤.

ë”°ë¼ì„œ ì´ë²ˆì—” ë¶„ì„í•  Binary Classification with a Bank Churn Datasetì€ Santander Customer Satisfaction dataì™€ titanic dataë¥¼ ì„ì–´ ë†“ì€ ë°ì´í„°ë¼ê³  í•  ìˆ˜ ìˆë‹¤.

---

### í”„ë¡œì íŠ¸ ê°œìš”
##### ğŸ“Œ ëª©í‘œ
kaggleì—ì„œ ì—…ë¡œë“œí•œ overviewëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

![image](https://github.com/user-attachments/assets/c043d858-8be7-43d8-b19d-b0f2d9268575)

ì¦‰, ê³ ê°ì´ ê³„ì†í•´ì„œ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í• ì§€ ì•„ë‹ˆë©´ ê³„ì •ì„ ë‹«ê³  ì„œë¹„ìŠ¤ë¥¼ ì¤‘ë‹¨í• ì§€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒìœ¼ë¡œ ì´ì§„ë¶„ë¥˜ ë¬¸ì œì´ë‹¤

##### ğŸ–¥ï¸ ë°ì´í„°ì…‹ (Data Set)
ì´ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•œ ë°ì´í„°ì…‹ì€ Kaggleì—ì„œ ì œê³µí•˜ëŠ” ë‹¤ìŒ íŒŒì¼ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
1. train.csv: í›ˆë ¨ ë°ì´í„°ì…‹, íŠ¹ì§•ë“¤ê³¼ ëª©í‘œ ë³€ìˆ˜ë¥¼ í¬í•¨.
2. test.csv: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹, ì˜ˆì¸¡ì„ ìœ„í•´ ì‚¬ìš©ë  ë°ì´í„°.
3. sample_submission.csv: ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì œì¶œí•˜ê¸° ìœ„í•œ ìƒ˜í”Œ íŒŒì¼.

---

##### ë°©ë²•ë¡ 
1. ë¬¸ì œì— ëŒ€í•œ ì •ë³´ ìˆ˜ì§‘
  * ë¬¸ì œ ì •ì˜
2. Bank Churn Data setì„ ì´ìš©í•œ EDA ë° Data Cleaning
  * ê³µí†µ ì½”ë“œ
  * ë¶„ì„
    * Bank Churn Data setì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ì •ë³´
    * feature ë¶„ì„
    * Data cleaning
    * Feature Engineering
3. ëª¨ë¸ í•™ìŠµ
  * XGBoost
  * LightGBM
  * CatBoost
  * Data Leakage
4. ê²°ë¡ 
  * í•œê³„ì 

---

### ë¬¸ì œì— ëŒ€í•œ ì •ë³´ ìˆ˜ì§‘
   #### 1. ë¬¸ì œ ì •ì˜
Bank Churn Datasetì€ kaggleì—ì„œ 2024ë…„ì„ ë§ì´í•´ ì œê³µí•œ ê²ƒìœ¼ë¡œ ê³ ê° ì´íƒˆ(Churn) ì˜ˆì¸¡ì„ ì§„í–‰í•˜ëŠ” ê²ƒì´ë‹¤. ì¦‰, ê³ ê°ì´ ê³„ì†í•´ì„œ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í• ì§€ ì•„ë‹ˆë©´ ê³„ì •ì„ ë‹«ê³  ì„œë¹„ìŠ¤ë¥¼ ì¤‘ë‹¨í• ì§€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒìœ¼ë¡œ ì´ì§„ë¶„ë¥˜ ë¬¸ì œì´ë‹¤. ë‹¤ë§Œ ì´ë²ˆ kaggle ëŒ€íšŒëŠ” ì´íƒˆí•  ê°€ëŠ¥ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì˜ˆì¸¡í•˜ëŠ” ê²ƒìœ¼ë¡œ ì œì¶œí•  ë•ŒëŠ” ì´ì§„ ë¶„ë¥˜ì˜ í™•ë¥  ê°’ì„ ì œì¶œí•´ì•¼ í•œë‹¤. ì¦‰, ì˜ˆì¸¡í•œ ê°’ì´ 0 ë˜ëŠ” 1ê³¼ ê°™ì€ ì´ì§„ ê°’ì´ ì•„ë‹Œ, 0ê³¼ 1 ì‚¬ì´ì˜ í™•ë¥ ì´ì–´ì•¼ í•˜ë¯€ë¡œ íšŒê·€ì²˜ëŸ¼ ë³´ì¼ ìˆ˜ ìˆì§€ë§Œ, ê·¼ë³¸ì ìœ¼ë¡œëŠ” ë¶„ë¥˜ ë¬¸ì œì´ë‹¤.

ì œê³µë˜ëŠ” ë°ì´í„°ëŠ” train.csv, test.csv, sample_submission.scv ì„¸ ê°œì˜ íŒŒì¼ë¡œ train.csvë¥¼ í† ëŒ€ë¡œ test.csvì˜ ê³ ê° ì´íƒˆ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œì´ë‹¤. ì´í›„ sample_submission.csvì— ì…ë ¥í•œ í›„ ì œì¶œí•˜ëŠ” í•´ë‹¹ íŒŒì¼ì„ ì œì¶œí•˜ëŠ” ê²ƒì´ë‹¤.

### Santander Customer Satisfaction data setì„ ì´ìš©í•œ EDA
   #### 1. ê³µí†µ ì½”ë“œ
import libraries and files
```
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import optuna
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve, roc_curve, classification_report, roc_auc_score
from lightgbm import LGBMClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
import warnings
warnings.filterwarnings('ignore')

RANDOM_STATE = 110
pd.set_option('display.max_columns', None)

train_df = pd.read_csv("../../data/Bank_Churn_Dataset/train.csv")
test_df = pd.read_csv("../../data/Bank_Churn_Dataset/test.csv")
submission_df = pd.read_csv("../../data/Bank_Churn_Dataset/sample_submission.csv")
```
í•„ìì˜ ê²½ìš° íŒŒì¼ì„ ë”°ë¡œ ì €ì¥í•´ ë‘ëŠ” í´ë”ê°€ ìˆê¸° ë•Œë¬¸ì— ê·¸ê³³ì— ì €ì¥ì„ í•´ë‘ê³  ìˆë‹¤. ë”°ë¼ì„œ ì½”ë“œê°€ í•´ë‹¹ í´ë”ë¥¼ ì°¾ì•„ê°€ì•¼ í•˜ê¸° ë•Œë¬¸ì— ìœ„ì™€ ê°™ì´ ì‘ì„±ëœ ê²ƒì´ë‹¤.

í‰ê°€ë¥¼ ìœ„í•œ í•¨

![image](https://github.com/user-attachments/assets/6c67834d-b07c-4faa-adf9-85762112d42a)

kaggleì—ì„œ ê³µì§€í•œ í‰ê°€ ë°©ì‹ì€ ìœ„ì™€ ê°™ë‹¤. ROC ê³¡ì„  ì•„ë˜ì˜ ë©´ì (AUC)ì´ ëª¨ë¸ì˜ ìµœì¢… ì„±ëŠ¥ ì§€í‘œë¡œ ì‚¬ìš©ëœë‹¤. ì¦‰, AUC-ROCëŠ” ëª¨ë¸ì´ íƒ€ê²Ÿ í´ë˜ìŠ¤(ì´íƒˆ ë˜ëŠ” ìœ ì§€)ë¥¼ ì–¼ë§ˆë‚˜ ì˜ êµ¬ë¶„í•˜ëŠ”ì§€ í‰ê°€í•˜ëŠ” ì¤‘ìš”í•œ ì§€í‘œì´ë‹¤. ë”°ë¼ì„œ ì˜¤ì°¨í–‰ë ¬, ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1 Score, AUCë¥¼ ëª¨ë‘ í™•ì¸í•  ê²ƒì´ë‹¤.

   #### 2. ë¶„ì„
   ##### 1. Bank Churn Data setì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ì •ë³´
```
train_df.shape
test_df.shape
submission_df.shape

(165034, 14)
(110023, 13)
(110023, 2)
```
ìœ„ì™€ ê°™ì´ ì¶œë ¥ëœë‹¤. ì¦‰, train_dfë¡œ ëª¨ë¸ì„ í•™ìŠµì„ í•œ í›„ test_dfë¥¼ ì˜ˆì¸¡í•œ ë‹¤ìŒ submission_dfì— ì…ë ¥í•´ ì œì¶œí•˜ëŠ” ê²ƒì´ë‹¤.

train_dfëŠ” indexì™€ idë¥¼ ì œì™¸í•œ 12ê°œì˜ featureë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©° ì•„ë˜ dataframeê³¼ ê°™ë‹¤.

![image](https://github.com/user-attachments/assets/7ba94325-baa0-41a4-bb4d-8eca5c37aeea)

ê°ê° featureì— ëŒ€í•œ ì„¤ëª…ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

* Surname: ì„±(ì´ë¦„)
* CreditScore: ì‹ ìš© ì ìˆ˜
* Geography: ê±°ì£¼ êµ­ê°€
* Gender: ì„±
* Age: ë‚˜ì´
* Tenure: ì€í–‰ì„ ì´ìš©í•œ ê¸°ê°„
* Balance: ê³„ì¢Œ ì”ì•¡
* NumOfProducts: ì´ìš©í•˜ëŠ” ì€í–‰ ìƒí’ˆì˜ ìˆ˜(ex. ì˜ˆê¸ˆ,ì ê¸ˆ)
* HasCrCard: ì‹ ìš©ì¹´ë“œ ë³´ìœ  ì—¬ë¶€
* IsActiveMember: í™œì„± íšŒì› ì—¬ë¶€
* EstimatedSalary: ì˜ˆìƒ ì—°ë´‰
* Exited: ì´íƒˆ ì—¬ë¶€

```
train_df.describe()
```
![image](https://github.com/user-attachments/assets/a21cdec6-6ad2-42ad-b97d-8ad6cc21f0ea)

ëŒ€ëµì ìœ¼ë¡œ ë³¼ ë•Œ ì´ìƒì¹˜ê°€ ë³´ì´ì§€ëŠ” ì•Šë‹¤. ë‹¤ë§Œ CreditScoreì™€ Ageê°€ ë„“ê²Œ ë¶„í¬í•œ ê²ƒì€ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ë²”ìœ„ë¥¼ íŠ¹ì •í•´ì„œ êµ¬ë¶„í•˜ëŠ” ê²ƒë„ ì¢‹ì€ ë°©ë²•ì´ë¼ê³  ìƒê°í•œë‹¤.

```
target_cnt = train_df['Exited'].count()
print(train_df['Exited'].value_counts())
train_df['Exited'].value_counts() / target_cnt

Exited
0    130113
1     34921

Exited
0    0.788401
1    0.211599
```
Exitedì— ëŒ€í•œ  countë¥¼ ë³´ë©´ ë¶ˆê· í˜•ì ì¸ ë°ì´í„°ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ sampling ì‘ì—…ì´ ì¶”ê°€ì ìœ¼ë¡œ í•„ìš”í•˜ë‹¤.

   ##### 2. Data cleaning
1. data setì— ëª¨ë“  ê°’ì´ NaNì¸ ì»¬ëŸ¼ì„ í™•ì¸ ë° drop
```
all_nan_columns = train_df.columns[train_df.isna().all()].tolist()
print(f"ëª¨ë“  ê°’ì´ NaNì¸ ì»¬ëŸ¼ ê°œìˆ˜: {len(all_nan_columns)}")

train_df.drop(columns=all_nan_columns, inplace=True, axis=1)
test_df.drop(columns=all_nan_columns, inplace=True, axis=1)
```
ì´ë¯¸ ì•ì—ì„œ í™•ì¸í–ˆë“¯ ê²°ê³¼ëŠ” 0ê°œë¡œ ì—†ë‹¤.

2. ê³ ìœ ê°’ì´ 1ì¸ ì»¬ëŸ¼ í™•ì¸ ë° drop
```
unique_one_columns = [col for col in train_df.columns if train_df[col].nunique() == 1]
print(f'ê³ ìœ ê°’ì´ 1ì¸ ì»¬ëŸ¼ ê°œìˆ˜: {len(unique_one_columns)}')

train_df.drop(columns=unique_one_columns, inplace=True, axis=1)
test_df.drop(columns=unique_one_columns, inplace=True, axis=1)
```
3. ì¤‘ë³µ ë°ì´í„° drop
```
train_df.drop(['id', 'CustomerId'], axis=1, inplace=True)
test_df.drop(['id', 'CustomerId'], axis=1, inplace=True)
```
ì¤‘ë³µ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ì „ì— idì™€ CustomerIdë¥¼ ë¨¼ì € dropí•œ í›„ ì§„í–‰í–ˆë‹¤.
```
train_df.duplicated().sum()
```
54ê°œì˜ ì¤‘ë³µëœ ë°ì´í„°ê°€ ìˆë‹¤. ì¦‰, 54ê°œì˜ í–‰ì´ ë‹¤ë¥¸ í–‰ê³¼ ë™ì¼í•œ ê°’ì„ ê°€ì§€ê³  ìˆë‹¤ëŠ” ëœ»ì´ë‹¤. ì¤‘ë³µëœ ë°ì´í„°ê°€ ì¤‘ìš”í•œ ë°ì´í„°ì¸ì§€ í™•ì¸ì„ í•œ í›„ì— dropì„ í•´ì•¼ í•œë‹¤. 

ì˜ˆë¥¼ ë“¤ì–´ ì„¤ë¬¸ ì¡°ì‚¬ë‚˜ íˆ¬í‘œì™€ ê°™ì€ ë°ì´í„°ì—ì„œëŠ” ë™ì¼í•œ ì‘ë‹µì´ ì—¬ëŸ¬ ë²ˆ ìˆì„ ìˆ˜ ìˆìœ¼ë©°, ì´ëŸ° ë°ì´í„°ëŠ” ì¤‘ìš”í•œ ê°’ì´ê¸° ë•Œë¬¸ì´ë‹¤. ë°˜ë©´ ì¤‘ë³µìœ¼ë¡œ ìˆ˜ì§‘ëœ ë°ì´í„°ë¼ë©´ ì‚­ì œí•´ë„ ë˜ëŠ” ë°ì´í„°ì´ë‹¤. ë”°ë¼ì„œ í™•ì¸ì´ í•„ìš”í•˜ë‹¤.
```
duplicate_all = train_df[train_df.duplicated(keep=False)]
duplicate_all[duplicate_all['Surname']== 'Cunningham']
```
![image](https://github.com/user-attachments/assets/8dd98264-6b49-4a58-b600-b6a547c41653)

ë‹¤ìŒê³¼ ê°™ì´ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ Cunninghamì´ë€ ì„±ì„ ê°€ì§„ ì‚¬ëŒì˜ ë°ì´í„°ë¥¼ ì¶œë ¥í•œ ê²ƒìœ¼ë¡œ idì™€ CustomerIdëŠ” ë‹¤ë¥´ì§€ë§Œ ë‹¤ë¥¸ ê²ƒì€ ëª¨ë‘ ê°™ë‹¤. ì‹ ìš©ì ìˆ˜, ë‚˜ì´, ê±°ì£¼ êµ­ê°€, ì„±ë³„, ë‚˜ì´, ì€í–‰ ì´ìš© ê¸°ê°„, ê³„ì¢Œ ì”ì•¡ ë“± ì „ë¶€ ê°™ë‹¤. íŠ¹íˆ, í•„ìëŠ” ì„œë¡œ ë‹¤ë¥¸ ì‚¬ëŒì´ ì‹ ìš©ì ìˆ˜, ë‚˜ì´, ì€í–‰ ì´ìš© ê¸°ê°„, ì˜ˆìƒ ì—°ë´‰ ëª¨ë‘ ê°™ë‹¤ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥ í•˜ë‹¤ ìƒê°í•˜ê¸° ë•Œë¬¸ì— ì‚­ì œí•˜ê¸°ë¡œ í–ˆë‹¤.
```
train_df = train_df.drop_duplicates()
```
4. ì¤‘ë³µëœ ë°ì´í„° ì¤‘ì—ì„œ íƒ€ê²Ÿ ê°’(Exited)ì´ ë‹¤ë¥¸ ë°ì´í„° ì°¾ê¸° - noise ì°¾ê¸°
```
y = train_df['Exited']
X = train_df.drop(['Exited'], axis=1)

train_with_target = pd.concat([X, y], axis=1)

duplicates = train_with_target.duplicated(keep=False)
duplicates_with_different_target = duplicates & (train_with_target.groupby(list(X.columns))['Exited'].transform('nunique') > 1)

noise = train_with_target[duplicates_with_different_target]
cleaned_train = train_with_target[~duplicates_with_different_target]

X = cleaned_train.drop('Exited', axis=1)
y = cleaned_train['Exited']
```
noise ë°ì´í„°ëŠ” ì—†ë‹¤. ë”°ë¼ì„œ ì—¬ê¸°ì„œ Data cleaning ì‘ì—…ì€ ë§ˆë¬´ë¦¬ í•˜ê² ë‹¤.

   ##### 2. Data cleaning
1. ìƒê´€ê´€ê³„
ìˆ«ìí˜• featureì— ëŒ€í•´ ìƒê´€ê´€ê³„ë¥¼ ë³´ê² ë‹¤. ì•„ë˜ ì½”ë“œë¥¼ ì…ë ¥í•˜ë©´ ì•„ë˜ ì‚¬ì§„ì²˜ëŸ¼ ìƒê´€ê´€ê³„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ëª¨ë“  ì»¬ëŸ¼ì´ ìê¸° ìì‹ ì„ ë¹¼ê³  ì—°ê´€ì´ ê±°ì˜ ì—†ë‹¤.
```
numeric_df = train_df.select_dtypes(include=['float', 'int']).columns
numeric_df = train_df[numeric_df]

corr = numeric_df.corr()
corr.style.background_gradient(cmap='coolwarm')
```
![image](https://github.com/user-attachments/assets/2a424c73-87b9-490e-99e4-819990dbe076)

2. Age

ë‚˜ì´ëŠ” ì€í–‰ ì„œë¹„ìŠ¤ë¥¼ ê³„ì† ì´ìš©í• ì§€ ì•ˆ í• ì§€ë¥¼ ê²°ì •í•˜ëŠ” ë° ì¢‹ì€ ë°ì´í„°ë¼ê³  ìƒê°í•œë‹¤. ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ê³ ê°ì˜ ë‚˜ì´ì— ë”°ë¼ ê¸ˆìœµ ì„œë¹„ìŠ¤ì— ëŒ€í•œ í•„ìš”ì™€ ì„ í˜¸ê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì´ë‹¤. ì¦‰ ì Šì€ ì¸µì€ ì€í–‰ì´ë‚˜ ê¸ˆìœµ ì„œë¹„ìŠ¤ë¥¼ ì ê·¹ì ìœ¼ë¡œ ë¹„êµí•˜ë©°, ë” ë‚˜ì€ í˜œíƒì´ë‚˜ ë” í¸ë¦¬í•œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ë‹¤ë¥¸ ê¸ˆìœµ ê¸°ê´€ìœ¼ë¡œ ì´íƒˆí•  ê°€ëŠ¥ì„±ì´ í¬ë©°, ë‚˜ì´ê°€ ë§ì€ ê³ ê°ì€ ê¸°ì¡´ì˜ ê¸ˆìœµ ì„œë¹„ìŠ¤ì— ìµìˆ™í•´ì ¸ ìˆìœ¼ë©°, ì„œë¹„ìŠ¤ ë³€ê²½ì— ë”°ë¥¸ ë¶ˆí¸ì„ í”¼í•˜ë ¤ê³  í•˜ê¸° ë•Œë¬¸ì— ì„œë¹„ìŠ¤ë¥¼ ìœ ì§€í•˜ëŠ” ê²½í–¥ì´ ìˆì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤.

ë‚˜ì´ì˜ ë¶„í¬ê°€ 18~92ê¹Œì§€ ë‹¤ì–‘í•˜ê²Œ ìˆë‹¤. ë”°ë¼ì„œ ì—°ë ¹ëŒ€ë¥¼ íŠ¹ì • êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì‘ì—…ì„ í•˜ê² ë‹¤.
```
def get_age(age):
    cat = ''
    if age <= 23: cat = 'Student'
    elif age <= 39: cat = 'Young Adult'
    elif age <= 64: cat = 'Adult'
    else: cat = 'Elderly'        
    return cat

group_names = ['Student', 'Young Adult', 'Adult', 'Elderly']
 
train_df['Age_range'] = train_df['Age'].apply(lambda x : get_age(x))
test_df['Age_range'] = test_df['Age'].apply(lambda x : get_age(x))
```
```
age_range_counts = train_df.groupby('Age_range')['Exited'].value_counts(normalize=True).unstack()
age_range_counts
```
![image](https://github.com/user-attachments/assets/88fc4b86-3dd4-4007-89ce-1f41b5d70f16)

ê²°ê³¼ë¥¼ ë³´ë©´ í•„ìê°€ ì˜ˆìƒí•œ ê²ƒê³¼ ë‹¤ë¥´ê²Œ Adultì—ì„œ ì´íƒˆ ê³ ê°ì´ ê°€ì¥ ë§ì•˜ê³  ë‹¤ìŒìœ¼ë¡œ Elderlyê°€ ë§ì•˜ë‹¤. Student, Young Adultê°€ ì´íƒˆ ê³ ê°ì´ ì ì—ˆë‹¤. ë”°ë¼ì„œ ë‹¤ë¥¸ ë°ì´í„°ë¥¼ í™•ì¸í•´ ë³¼ í•„ìš”ê°€ ìˆë‹¤.

3. NumOfProduct

ì€í–‰ì—ì„œ ì´ìš©í•˜ëŠ” ìƒí’ˆì˜ ìˆ˜ì´ë‹¤. ìƒí’ˆì˜ ìˆ˜ê°€ ë§ìœ¼ë©´ ë‹¤ë¥¸ ì€í–‰ì—ì„œë„ ê±°ë˜ë¥¼ í•˜ê³  ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ì•„ ì´íƒˆ ê°€ëŠ¥ì„±ì´ ë” ë†’ì„ ìˆ˜ ìˆë‹¤. ë¬¼ë¡  ë§ì€ ìƒí’ˆì„ ì´ìš©í•˜ëŠ” ê³ ê°ì€ í•´ë‹¹ ì€í–‰ê³¼ ë” ê¹Šì€ ê´€ê³„ë¥¼ í˜•ì„±í•˜ê¸° ë•Œë¬¸ì— ì´íƒˆí•  ê°€ëŠ¥ì„±ì´ ì ì„ ìˆ˜ë„ ìˆë‹¤.
```
Products_exited_counts = numeric_df.groupby('NumOfProducts')['Exited'].value_counts(normalize=True).unstack()
Products_exited_counts
```
![image](https://github.com/user-attachments/assets/5342a783-c3c4-4c43-be1f-860eab26a794)

ê²°ê³¼ëŠ” ìƒí’ˆì„ ë§ì´ ì‚¬ìš©í•  ìˆ˜ë¡ ì´íƒˆí•˜ëŠ” ì‚¬ëŒì´ ì•ë„ì ìœ¼ë¡œ ë†’ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. (ë³¸ ë°ì´í„°ëŠ” ì‹¤ì œ ì€í–‰ ë°ì´í„°ê°€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì‹¤ì œì™€ ë‹¤ë¥¼ ìˆ˜ ìˆë‹¤.) íŠ¹íˆ, 1ê°œë¥¼ ì´ìš©í•  ë•Œ ì—­ì‹œ ì´íƒˆìœ¨ì´ ë†’ë‹¤ëŠ” ê²ƒë„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
```
train_df.groupby('Age_range')['NumOfProducts'].value_counts(normalize=True).unstack()
```
![image](https://github.com/user-attachments/assets/9a0dd1a3-09d9-4686-b7a4-325c2649029f)

ì—°ë ¹ëŒ€ê°€ ë†’ì„ ìˆ˜ë¡ ì€í–‰ì—ì„œ ì´ìš©í•˜ëŠ” ìƒí’ˆ ìˆ˜ê°€ ë§ë‹¤. ì „ì²´ì ìœ¼ë¡œ ë³´ë©´ ì „ì²´ ì—°ë ¹ëŒ€ì—ì„œ 1~2ê°œë¥¼ ì´ìš©í•˜ëŠ” ë¹„ìœ¨ì´ ë†’ì§€ë§Œ ì´íƒˆìœ¨ì´ ê°€ì¥ ë§ì€ Adult, Elderlyì—ì„œ 1ê°œë§Œ ì´ìš©í•˜ëŠ” ë¹„ìœ¨ì´ ë†’ìœ¼ë©° 3~4ê°œë¥¼ ì´ìš©í•˜ëŠ” ë¹„ìœ¨ ì—­ì‹œ ë†’ë‹¤. ì•„ë˜ í‘œëŠ” Adult, Elderlyì¼ ë•Œ Studentì™€ Young Adult ê°„ì˜ ì´ìš© ìƒí’ˆ ìˆ˜ê°€ 3~4ê°œ ì¼ ë•Œì˜ ë¹„ìœ¨ì„ ë¹„êµí•œ ê²ƒì´ë‹¤. ì´ë ‡ê²Œ ë¹„êµë¥¼ í†µí•´ Adultì™€ Elderlyê°€ ì´íƒˆ ê°€ëŠ¥ì„±ì´ ë” ë†’ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

<img width="716" alt="image" src="https://github.com/user-attachments/assets/bc8cc872-2ee9-464d-8a01-63fdbfa456b4">


4. Tenure - ì€í–‰ ì´ìš© ê¸°ê°„

ì€í–‰ ì´ìš© ê¸°ê°„ ì—­ì‹œ ì€í–‰ ì„œë¹„ìŠ¤ ì´ìš©ì— ìˆì–´ í° ì˜í–¥ì„ ì¤„ ê²ƒìœ¼ë¡œ ìƒê°í•˜ê³  ìˆë‹¤. ê·¸ ì´ìœ ëŠ” ì‹ ìš© ì¹´ë“œ, ëŒ€ì¶œ, ì €ì¶• ê³„ì¢Œ ë“±ì„ ì—¬ëŸ¬ í•´ ë™ì•ˆ ì´ìš©í–ˆì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì˜¤ëœ ê¸°ê°„ ì´ìš©í•  ê²½ìš° ì€í–‰ì— í° ì‹¤ë§ì„ í•˜ì§€ ì•ŠëŠ” ì´ìƒ ì€í–‰ì„ ë°”ê¾¸ì§€ ì•Šê¸° ë•Œë¬¸ì´ë‹¤.

```
tenure_exited_counts = numeric_df.groupby('Tenure')['Exited'].value_counts(normalize=True).unstack()
tenure_exited_counts
```
![image](https://github.com/user-attachments/assets/415f639a-b410-4f3d-8db4-15977144d4ba)

í•˜ì§€ë§Œ ì˜ˆìƒê³¼ ë‹¤ë¥´ê²Œ ê¸°ê°„ì´ ê¸¸ ë‹¤ê³  ì´íƒˆìœ¨ì´ ë†’ì€ ê²ƒì€ ì•„ë‹ˆì˜€ë‹¤. ë¬¼ë¡  Tenure ì¦‰, ì´ìš© ê¸°ê°„ì´ 0ì¼ ë•Œ ì´íƒˆìœ¨ì´ ê°€ì¥ ë†’ì§€ë§Œ ëŒ€ì²´ì ìœ¼ë¡œ ë¹„ìŠ·í•˜ë‹¤.

ì´ë²ˆì—ëŠ” ì´ìš© ê¸°ê°„ ë™ì•ˆ ì–¼ë§ˆë‚˜ ë§ì€ ìƒí’ˆì„ ì´ìš©í–ˆëŠ” ê°€ë¥¼ ê³„ì‚°í•´ì„œ ì»¬ëŸ¼ìœ¼ë¡œ ë§Œë“¤ì–´ ë³´ê² ë‹¤.
```
train_df['Products_Per_Tenure'] =  train_df['Tenure'] / train_df['NumOfProducts']
test_df['Products_Per_Tenure'] =  test_df['Tenure'] / test_df['NumOfProducts']
```
```
products_per_tenure_counts = train_df.groupby('Products_Per_Tenure')['Exited'].value_counts(normalize=True).unstack()

products_per_tenure_counts.plot(kind='bar', stacked=True, figsize=(12, 6))

plt.xlabel('Products per Tenure')
plt.ylabel('Proportion of Exited')
plt.legend(title='Exited', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```
![image](https://github.com/user-attachments/assets/ba9037b5-19ef-4848-861e-58fef06ece27)

ëª¨ë“  ê²½ìš°ì—ì„œ ì ìš©ë˜ëŠ” ê²ƒì€ ì•„ë‹ˆì§€ë§Œ ìƒí’ˆì„ ë§ì´ ì´ìš©í–ˆì„ ë•Œ ì´íƒˆìœ¨ì´ ì ê³  ì ê²Œ ì´ìš©í–ˆì„ ë•Œ ì´íƒˆìœ¨ì´ ë†’ë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

 

5. CreditScore

CreditScore ì—­ì‹œ Ageì™€ ë¹„ìŠ·í•˜ê²Œ ë‹¤ì–‘í•˜ê²Œ ìˆê¸° ë•Œë¬¸ì— íŠ¹ì • êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ê² ë‹¤. ë¯¸êµ­ ì‹ ìš© ì ìˆ˜ì¸ Fico Scoreë¥¼ ê¸°ì¤€ìœ¼ë¡œ í–ˆë‹¤. ì‹ ìš© ì ìˆ˜ê°€ ë†’ì€ ê³ ê°ì€ ì¬ì •ì ìœ¼ë¡œ ì•ˆì •ì ì´ë©°, ë” ë§ì€ ê¸ˆìœµ ìƒí’ˆ(ëŒ€ì¶œ, ì‹ ìš© ì¹´ë“œ ë“±)ì„ ì´ìš©í•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤. ë˜í•œ, ì€í–‰ê³¼ì˜ ê´€ê³„ê°€ ê¸ì •ì ì¼ ê°€ëŠ¥ì„±ì´ í¬ê¸° ë•Œë¬¸ì— ì´íƒˆ ê°€ëŠ¥ì„±ì´ ë‚®ì„ ìˆ˜ ìˆë‹¤.
```
def get_fico(age):
    cat = ''
    if age <= 579: cat = 'Poor'
    elif age <= 669: cat = 'Not_Good'
    elif age <= 799: cat = 'Very_Good'
    else: cat = 'Excellent'        
    return cat

group_names = ['Poor', 'Not_Good', 'Very_Good', 'Excellent']
 
train_df['Fico_Score'] = train_df['CreditScore'].apply(lambda x : get_fico(x))
test_df['Fico_Score'] = test_df['CreditScore'].apply(lambda x : get_fico(x))
```
```
credit_exited_counts = train_df.groupby('Fico_Score')['Exited'].value_counts(normalize=True).unstack()
credit_exited_counts
```
![image](https://github.com/user-attachments/assets/50a9b73f-4f35-4791-ae6c-e2f05eca6077)

ì˜ˆìƒê³¼ ë‹¤ë¥´ê²Œ íŠ¹ë³„í•˜ê²Œ í° ì°¨ì´ê°€ ë³´ì´ì§€ëŠ” ì•Šì§€ë§Œ Poor êµ¬ê°„ì—ì„œ ê°€ì¥ ë†’ì€ ì´íƒˆìœ¨ì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤.

6. Balance(ê³„ì¢Œ ì”ì•¡), EstimatedSalary(ì˜ˆìƒ ì—°ë´‰)

ê³„ì¢Œ ì”ì•¡ê³¼ ì˜ˆìƒ ì—°ë´‰ì€ ê°™ì´ ë¹„êµë¥¼ í•˜ê² ë‹¤. ì´ìœ ëŠ” ëŒ€ë¶€ë¶„ ì—°ë´‰ì´ ë†’ì„ ìˆ˜ë¡ ê³„ì¢Œ ì”ì•¡ì´ ë§ê¸° ë•Œë¬¸ì´ë‹¤. ë‘ ë°ì´í„°ëŠ” ê³ ê°ì˜ ì¬ì •ì  ì•ˆì •ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œë¡œ ì¤‘ìš”í•˜ë‹¤.
```
train_df['Balance_to_EstimatedSalary'] = train_df['Balance'] / train_df['EstimatedSalary']
test_df['Balance_to_EstimatedSalary'] = test_df['Balance'] / test_df['EstimatedSalary']
```
```
credit_exited_counts = train_df.groupby('Balance_to_EstimatedSalary')['Exited'].value_counts(normalize=True).unstack()
credit_exited_counts
```
![image](https://github.com/user-attachments/assets/51120ece-aae2-4b1f-a7d6-afc6848feb4c)

```
nan_exited_1 = credit_exited_counts[credit_exited_counts[1].isna()]
nan_exited_1
```
![image](https://github.com/user-attachments/assets/7107020c-3ff9-4c69-9f07-27e26055ff92)

ë§ì€ í–‰ì—ì„œ 1ì´ NaN ê°’ì´ë‹¤. í•˜ì§€ë§Œ  ë³´ìœ  ê¸ˆì•¡ê³¼ ì˜ˆìƒ ì—°ë´‰ì´ ì´íƒˆìœ¨ê³¼ëŠ” í¬ê²Œ ì—°ê´€ì´ ì—†ëŠ” ê²ƒ ê°™ë‹¤.

7. category feature
```
sum_columns = ['Surname', 'Geography', 'Gender']
```
ìœ„ì˜ ì„¸ ê°œì˜ featureê°€ ì•„ì§ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë‚¨ì€ featureë‹¤ Surnameì˜ ê²½ìš° ì„±(ì´ë¦„)ìœ¼ë¡œ êµ­ê°€, ì„±ë³„ê³¼ ê²°í•©í•˜ë©´ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì¤„ ìˆ˜ ìˆë‹¤ê³  ì˜ˆìƒí•˜ê³  ìˆì–´ì„œ ê²°í•©í•˜ê¸°ë¡œ í–ˆë‹¤.
```
train_df['Surename_Geography_Gender'] = train_df[sum_columns].apply(lambda x: '_'.join(x.astype(str)), axis=1)
test_df['Surename_Geography_Gender'] = test_df[sum_columns].apply(lambda x: '_'.join(x.astype(str)), axis=1)
train_df
```
ê²°ê³¼ì ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì´ featureê°€ ë§Œë“¤ì–´ ì¡Œë‹¤.
![image](https://github.com/user-attachments/assets/91b92fa3-bb9a-455e-a22e-c082c48e65e2)




